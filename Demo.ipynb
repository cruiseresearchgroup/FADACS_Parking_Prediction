{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T05:43:23.496211Z",
     "start_time": "2020-03-22T05:43:23.480938Z"
    }
   },
   "outputs": [],
   "source": [
    "import Trier as trier\n",
    "\n",
    "exp = trier.Experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T05:29:04.789017Z",
     "start_time": "2020-03-22T05:29:04.766394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ./eptest/t1  already exists\n"
     ]
    }
   ],
   "source": [
    "exp.setup(path = \"./eptest/t1\",    \n",
    "         start = \"01/09/2017\",    \n",
    "         end = \"01/13/2017\",\n",
    "         testStart = \"02/13/2017\",\n",
    "         testEnd = \"02/16/2017\",\n",
    "         number = 5,                #How many parking lots\n",
    "         location = \"MelbCity\",     #MelbCity or Mornington(not ready yet)\n",
    "         features = ['Temp', 'Wind', 'Humidity', 'Barometer', 'Extreme_weather', 'min_dis0.05', 'num_of_poi0.05', 'num_of_open_poi0.05', 'mean_dis0.05', 'min_dis0.1', 'num_of_poi0.1', 'num_of_open_poi0.1', 'mean_dis0.1', 'min_dis0.2', 'num_of_poi0.2', 'num_of_open_poi0.2', 'mean_dis0.2', 'min_dis0.3', 'num_of_poi0.3', 'num_of_open_poi0.3', 'mean_dis0.3', 'min_dis0.4', 'num_of_poi0.4', 'num_of_open_poi0.4', 'mean_dis0.4', 'min_dis0.5', 'num_of_poi0.5', 'num_of_open_poi0.5', 'mean_dis0.5', 'min_dis0.8', 'num_of_poi0.8', 'num_of_open_poi0.8', 'mean_dis0.8', 'min_dis1.0', 'num_of_poi1.0', 'num_of_open_poi1.0', 'mean_dis1.0', 'availability', 'Day', 'Hour', 'Minute', 'DayOfWeek', 'DayOfMonth', 'DayOfYear'],\n",
    "         reLoadExistDir = True)     #If True and a experiment exists in the path, it will reload it.\n",
    "                                    #If False, it would create/recreate a experiment in the path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload from a path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T05:44:20.939858Z",
     "start_time": "2020-03-22T05:44:20.927690Z"
    }
   },
   "outputs": [],
   "source": [
    "exp.loadConfig(\"./eptest/t1/exp.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train/Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T05:33:32.305728Z",
     "start_time": "2020-03-22T05:29:11.717644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare Train Datasets\n",
      "Generate X/Y Train Files!\n",
      "generate X/y Data for 4892\n",
      "generate X/y Data for 4718\n",
      "generate X/y Data for 4859\n",
      "generate X/y Data for 5111\n",
      "generate X/y Data for 3074\n",
      "./datasets/MelbCity/features/weather.csv\n",
      "./datasets/MelbCity/features/weather.csv\n",
      "./datasets/MelbCity/features/weather.csv\n",
      "./datasets/MelbCity/features/weather.csv\n",
      "./datasets/MelbCity/features/weather.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "100%|██████████| 4322/4322 [02:29<00:00, 28.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_y:(4322, 1, 120)\n",
      "_x:(4322, 30, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4322/4322 [02:32<00:00, 28.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_y:(4322, 1, 120)\n",
      "_x:(4322, 30, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4322/4322 [02:30<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_y:(4322, 1, 120)\n",
      "_x:(4322, 30, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4322/4322 [02:31<00:00, 28.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_y:(4322, 1, 120)\n",
      "_x:(4322, 30, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4322/4322 [02:31<00:00, 28.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_y:(4322, 1, 120)\n",
      "_x:(4322, 30, 45)\n",
      "Prepare Test Datasets\n",
      "Generate X/Y Test Files!\n",
      "generate X/y Data for 5111\n",
      "generate X/y Data for 3074\n",
      "generate X/y Data for 4718\n",
      "generate X/y Data for 4859\n",
      "generate X/y Data for 4892\n",
      "./datasets/MelbCity/features/weather.csv\n",
      "./datasets/MelbCity/features/weather.csv\n",
      "./datasets/MelbCity/features/weather.csv\n",
      "./datasets/MelbCity/features/weather.csv\n",
      "./datasets/MelbCity/features/weather.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['day'] = df1[\"datetime\"].str[:10]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['time'] = df1[\"datetime\"].str[11:]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"wd\"] = df1.apply(lambda row: arrow.get(row[\"datetime\"]).format(\"d\"), axis=1)\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = t+\" \"+dx[\"time\"]\n",
      "/home/jovyan/work/rmit-parking-prediction/FeatureConvertor.py:219: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dx[\"datetime\"] = end.format(\"YYYY-MM-DD HH:mm\")\n",
      "100%|██████████| 2882/2882 [01:03<00:00, 45.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_y:(2882, 1, 120)\n",
      "_x:(2882, 30, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2882/2882 [01:04<00:00, 44.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_y:(2882, 1, 120)\n",
      "_x:(2882, 30, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2882/2882 [01:04<00:00, 44.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_y:(2882, 1, 120)\n",
      "_x:(2882, 30, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2882/2882 [01:03<00:00, 45.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_y:(2882, 1, 120)\n",
      "_x:(2882, 30, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2882/2882 [01:05<00:00, 43.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_y:(2882, 1, 120)\n",
      "_x:(2882, 30, 45)\n"
     ]
    }
   ],
   "source": [
    "## execute only once!!!\n",
    "\n",
    "exp.prepareTTDatasets(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T05:27:42.707719Z",
     "start_time": "2020-03-22T05:27:42.626917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Experience da95ef0e-6bfd-11ea-894b-258eed843d36\n",
      "{\n",
      "  \"createDate\": [\n",
      "    \"2020-03-22 05:27:42\"\n",
      "  ],\n",
      "  \"model\": \"LightGBM\",\n",
      "  \"uuid\": \"da95ef0e-6bfd-11ea-894b-258eed843d36\"\n",
      "}\n",
      "Added Experience da9c4f66-6bfd-11ea-894b-258eed843d36\n",
      "{\n",
      "  \"createDate\": [\n",
      "    \"2020-03-22 05:27:42\"\n",
      "  ],\n",
      "  \"model\": \"FNN\",\n",
      "  \"parameters\": {\n",
      "    \"activation\": \"relu\",\n",
      "    \"batch_size\": 1000,\n",
      "    \"decay\": 0.01,\n",
      "    \"epochs\": 100,\n",
      "    \"learningRate\": 0.01,\n",
      "    \"loss\": \"mean_squared_error\",\n",
      "    \"momentum\": 0.9,\n",
      "    \"nesterov\": false,\n",
      "    \"verbose\": 1\n",
      "  },\n",
      "  \"uuid\": \"da9c4f66-6bfd-11ea-894b-258eed843d36\"\n",
      "}\n",
      "Added Experience da9d87e6-6bfd-11ea-894b-258eed843d36\n",
      "{\n",
      "  \"createDate\": [\n",
      "    \"2020-03-22 05:27:42\"\n",
      "  ],\n",
      "  \"model\": \"LSTM\",\n",
      "  \"parameters\": {\n",
      "    \"batch_size\": 1000,\n",
      "    \"epochs\": 100,\n",
      "    \"learningRate\": 0.01,\n",
      "    \"loss\": \"mae\",\n",
      "    \"mode\": \"min\",\n",
      "    \"monitor\": \"val_loss\",\n",
      "    \"nesterov\": false,\n",
      "    \"verbose\": 1\n",
      "  },\n",
      "  \"uuid\": \"da9d87e6-6bfd-11ea-894b-258eed843d36\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'da9d87e6-6bfd-11ea-894b-258eed843d36'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## execute only once!!!\n",
    "\n",
    "exp.add({\n",
    "    \"model\":\"LightGBM\"\n",
    "})\n",
    "\n",
    "exp.add({\n",
    "    \"model\":\"FNN\",\n",
    "    \"parameters\":{\n",
    "        \"batch_size\" : 1000,\n",
    "        \"epochs\" : 100,\n",
    "        \"learningRate\" : 0.01,\n",
    "        \"momentum\" : 0.9,\n",
    "        \"decay\" : 0.01,\n",
    "        \"nesterov\" : False,\n",
    "        \"loss\" :'mean_squared_error',\n",
    "        \"activation\" : \"relu\",\n",
    "        \"verbose\" : 1\n",
    "    }\n",
    "})\n",
    "\n",
    "exp.add({\n",
    "    \"model\":\"LSTM\",\n",
    "    \"parameters\":{\n",
    "        \"batch_size\" : 1000,\n",
    "        \"epochs\" : 100,\n",
    "        \"learningRate\" : 0.01,\n",
    "        \"monitor\" : 'val_loss',\n",
    "        \"mode\" : \"min\",\n",
    "        \"nesterov\" : False,\n",
    "        \"loss\" :'mae',\n",
    "        \"verbose\" : 1\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T05:36:17.736733Z",
     "start_time": "2020-03-22T05:36:17.727787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"createDate\": [\n",
      "    \"2020-03-22 05:27:42\"\n",
      "  ],\n",
      "  \"model\": \"LightGBM\",\n",
      "  \"uuid\": \"da95ef0e-6bfd-11ea-894b-258eed843d36\"\n",
      "}\n",
      "{\n",
      "  \"createDate\": [\n",
      "    \"2020-03-22 05:27:42\"\n",
      "  ],\n",
      "  \"model\": \"FNN\",\n",
      "  \"parameters\": {\n",
      "    \"activation\": \"relu\",\n",
      "    \"batch_size\": 1000,\n",
      "    \"decay\": 0.01,\n",
      "    \"epochs\": 100,\n",
      "    \"learningRate\": 0.01,\n",
      "    \"loss\": \"mean_squared_error\",\n",
      "    \"momentum\": 0.9,\n",
      "    \"nesterov\": false,\n",
      "    \"verbose\": 1\n",
      "  },\n",
      "  \"uuid\": \"da9c4f66-6bfd-11ea-894b-258eed843d36\"\n",
      "}\n",
      "{\n",
      "  \"createDate\": [\n",
      "    \"2020-03-22 05:27:42\"\n",
      "  ],\n",
      "  \"model\": \"LSTM\",\n",
      "  \"parameters\": {\n",
      "    \"batch_size\": 1000,\n",
      "    \"epochs\": 100,\n",
      "    \"learningRate\": 0.01,\n",
      "    \"loss\": \"mae\",\n",
      "    \"mode\": \"min\",\n",
      "    \"monitor\": \"val_loss\",\n",
      "    \"nesterov\": false,\n",
      "    \"verbose\": 1\n",
      "  },\n",
      "  \"uuid\": \"da9d87e6-6bfd-11ea-894b-258eed843d36\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "exp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify a experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T09:04:26.047651Z",
     "start_time": "2020-03-16T09:04:26.008206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Experience 58b41e9e-6742-11ea-b658-8d7a6e287413\n"
     ]
    }
   ],
   "source": [
    "exp.update(\"58b41e9e-6742-11ea-b658-8d7a6e287413\",{\n",
    "  \"model\": \"FNN\",\n",
    "  \"parameters\": {\n",
    "    \"activation\": \"relu\",\n",
    "    \"batch_size\": 2000,\n",
    "    \"decay\": 0.01,\n",
    "    \"epochs\": 100,\n",
    "    \"learningRate\": 0.01,\n",
    "    \"loss\": \"mean_squared_error\",\n",
    "    \"momentum\": 0.9,\n",
    "    \"nesterov\": False,\n",
    "    \"verbose\": 1\n",
    "  }\n",
    "})\n",
    "\n",
    "ep1.saveConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-22T05:43:33.761Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run all experiments! because no special experiment assigned\n",
      "Start Run da95ef0e-6bfd-11ea-894b-258eed843d36\n",
      "Start lightGBM [da95ef0e-6bfd-11ea-894b-258eed843d36] models Training and Test!\n",
      "Directory  ./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/  already exists\n",
      "lightGBM Training [t1] start!\n",
      "lightGBM Training Done [t1], spent: 4.52s\n",
      "lightGBM Training [t2] start!\n",
      "lightGBM Training Done [t2], spent: 4.31s\n",
      "lightGBM Training [t3] start!\n",
      "lightGBM Training Done [t3], spent: 4.46s\n",
      "lightGBM Training [t4] start!\n",
      "lightGBM Training Done [t4], spent: 4.66s\n",
      "lightGBM Training [t5] start!\n",
      "lightGBM Training Done [t5], spent: 4.37s\n",
      "lightGBM Training [t6] start!\n",
      "lightGBM Training Done [t6], spent: 4.38s\n",
      "lightGBM Training [t7] start!\n",
      "lightGBM Training Done [t7], spent: 4.42s\n",
      "lightGBM Training [t8] start!\n",
      "lightGBM Training Done [t8], spent: 4.43s\n",
      "lightGBM Training [t9] start!\n",
      "lightGBM Training Done [t9], spent: 4.44s\n",
      "lightGBM Training [t10] start!\n",
      "lightGBM Training Done [t10], spent: 4.55s\n",
      "lightGBM Training [t11] start!\n",
      "lightGBM Training Done [t11], spent: 4.50s\n",
      "lightGBM Training [t12] start!\n",
      "lightGBM Training Done [t12], spent: 4.48s\n",
      "lightGBM Training [t13] start!\n",
      "lightGBM Training Done [t13], spent: 4.50s\n",
      "lightGBM Training [t14] start!\n",
      "lightGBM Training Done [t14], spent: 4.52s\n",
      "lightGBM Training [t15] start!\n",
      "lightGBM Training Done [t15], spent: 4.57s\n",
      "lightGBM Training [t16] start!\n",
      "lightGBM Training Done [t16], spent: 2.16s\n",
      "lightGBM Training [t17] start!\n",
      "lightGBM Training Done [t17], spent: 3.32s\n",
      "lightGBM Training [t18] start!\n",
      "lightGBM Training Done [t18], spent: 3.87s\n",
      "lightGBM Training [t19] start!\n",
      "lightGBM Training Done [t19], spent: 2.82s\n",
      "lightGBM Training [t20] start!\n",
      "lightGBM Training Done [t20], spent: 3.47s\n",
      "lightGBM Training [t21] start!\n",
      "lightGBM Training Done [t21], spent: 2.63s\n",
      "lightGBM Training [t22] start!\n",
      "lightGBM Training Done [t22], spent: 2.53s\n",
      "lightGBM Training [t23] start!\n",
      "lightGBM Training Done [t23], spent: 2.41s\n",
      "lightGBM Training [t24] start!\n",
      "lightGBM Training Done [t24], spent: 2.16s\n",
      "lightGBM Training [t25] start!\n",
      "lightGBM Training Done [t25], spent: 2.79s\n",
      "lightGBM Training [t26] start!\n",
      "lightGBM Training Done [t26], spent: 2.41s\n",
      "lightGBM Training [t27] start!\n",
      "lightGBM Training Done [t27], spent: 2.54s\n",
      "lightGBM Training [t28] start!\n",
      "lightGBM Training Done [t28], spent: 2.44s\n",
      "lightGBM Training [t29] start!\n",
      "lightGBM Training Done [t29], spent: 2.38s\n",
      "lightGBM Training [t30] start!\n",
      "lightGBM Training Done [t30], spent: 2.47s\n",
      "lightGBM Training [t31] start!\n",
      "lightGBM Training Done [t31], spent: 2.94s\n",
      "lightGBM Training [t33] start!\n",
      "lightGBM Training Done [t33], spent: 3.02s\n",
      "lightGBM Training [t35] start!\n",
      "lightGBM Training Done [t35], spent: 2.88s\n",
      "lightGBM Training [t37] start!\n",
      "lightGBM Training Done [t37], spent: 2.54s\n",
      "lightGBM Training [t39] start!\n",
      "lightGBM Training Done [t39], spent: 2.24s\n",
      "lightGBM Training [t41] start!\n",
      "lightGBM Training Done [t41], spent: 2.85s\n",
      "lightGBM Training [t43] start!\n",
      "lightGBM Training Done [t43], spent: 2.72s\n",
      "lightGBM Training [t45] start!\n",
      "lightGBM Training Done [t45], spent: 2.91s\n",
      "lightGBM Training [t47] start!\n",
      "lightGBM Training Done [t47], spent: 2.49s\n",
      "lightGBM Training [t49] start!\n",
      "lightGBM Training Done [t49], spent: 2.75s\n",
      "lightGBM Training [t51] start!\n",
      "lightGBM Training Done [t51], spent: 3.01s\n",
      "lightGBM Training [t53] start!\n",
      "lightGBM Training Done [t53], spent: 3.26s\n",
      "lightGBM Training [t55] start!\n",
      "lightGBM Training Done [t55], spent: 3.17s\n",
      "lightGBM Training [t57] start!\n",
      "lightGBM Training Done [t57], spent: 3.33s\n",
      "lightGBM Training [t59] start!\n",
      "lightGBM Training Done [t59], spent: 3.12s\n",
      "lightGBM Training [t61] start!\n",
      "lightGBM Training Done [t61], spent: 2.06s\n",
      "lightGBM Training [t65] start!\n",
      "lightGBM Training Done [t65], spent: 2.23s\n",
      "lightGBM Training [t69] start!\n",
      "lightGBM Training Done [t69], spent: 3.35s\n",
      "lightGBM Training [t73] start!\n",
      "lightGBM Training Done [t73], spent: 3.52s\n",
      "lightGBM Training [t77] start!\n",
      "lightGBM Training Done [t77], spent: 3.52s\n",
      "lightGBM Training [t81] start!\n",
      "lightGBM Training Done [t81], spent: 3.20s\n",
      "lightGBM Training [t85] start!\n",
      "lightGBM Training Done [t85], spent: 3.26s\n",
      "lightGBM Training [t89] start!\n",
      "lightGBM Training Done [t89], spent: 3.09s\n",
      "lightGBM Training [t93] start!\n",
      "lightGBM Training Done [t93], spent: 3.75s\n",
      "lightGBM Training [t97] start!\n",
      "lightGBM Training Done [t97], spent: 2.06s\n",
      "lightGBM Training [t101] start!\n",
      "lightGBM Training Done [t101], spent: 2.09s\n",
      "lightGBM Training [t105] start!\n",
      "lightGBM Training Done [t105], spent: 2.07s\n",
      "lightGBM Training [t109] start!\n",
      "lightGBM Training Done [t109], spent: 2.06s\n",
      "lightGBM Training [t113] start!\n",
      "lightGBM Training Done [t113], spent: 2.08s\n",
      "lightGBM Training [t117] start!\n",
      "lightGBM Training Done [t117], spent: 2.07s\n",
      "lightGBM Training [t121] start!\n",
      "lightGBM Training Done [t121], spent: 2.10s\n",
      "lightGBM Training [t129] start!\n",
      "lightGBM Training Done [t129], spent: 2.07s\n",
      "lightGBM Training [t137] start!\n",
      "lightGBM Training Done [t137], spent: 2.06s\n",
      "lightGBM Training [t145] start!\n",
      "lightGBM Training Done [t145], spent: 2.06s\n",
      "lightGBM Training [t153] start!\n",
      "lightGBM Training Done [t153], spent: 2.15s\n",
      "lightGBM Training [t161] start!\n",
      "lightGBM Training Done [t161], spent: 2.11s\n",
      "lightGBM Training [t169] start!\n",
      "lightGBM Training Done [t169], spent: 2.07s\n",
      "lightGBM Training [t177] start!\n",
      "lightGBM Training Done [t177], spent: 2.09s\n",
      "lightGBM Training [t185] start!\n",
      "lightGBM Training Done [t185], spent: 2.09s\n",
      "lightGBM Training [t193] start!\n",
      "lightGBM Training Done [t193], spent: 2.11s\n",
      "lightGBM Training [t201] start!\n",
      "lightGBM Training Done [t201], spent: 2.05s\n",
      "lightGBM Training [t209] start!\n",
      "lightGBM Training Done [t209], spent: 2.07s\n",
      "lightGBM Training [t217] start!\n",
      "lightGBM Training Done [t217], spent: 2.07s\n",
      "lightGBM Training [t225] start!\n",
      "lightGBM Training Done [t225], spent: 2.05s\n",
      "lightGBM Training [t233] start!\n",
      "lightGBM Training Done [t233], spent: 2.05s\n",
      "lightGBM Training [t241] start!\n",
      "lightGBM Training Done [t241], spent: 2.09s\n",
      "lightGBM Training [t257] start!\n",
      "lightGBM Training Done [t257], spent: 2.06s\n",
      "lightGBM Training [t273] start!\n",
      "lightGBM Training Done [t273], spent: 2.07s\n",
      "lightGBM Training [t289] start!\n",
      "lightGBM Training Done [t289], spent: 2.06s\n",
      "lightGBM Training [t305] start!\n",
      "lightGBM Training Done [t305], spent: 2.10s\n",
      "lightGBM Training [t321] start!\n",
      "lightGBM Training Done [t321], spent: 2.05s\n",
      "lightGBM Training [t337] start!\n",
      "lightGBM Training Done [t337], spent: 2.08s\n",
      "lightGBM Training [t353] start!\n",
      "lightGBM Training Done [t353], spent: 2.06s\n",
      "lightGBM Training [t369] start!\n",
      "lightGBM Training Done [t369], spent: 2.06s\n",
      "lightGBM Training [t385] start!\n",
      "lightGBM Training Done [t385], spent: 2.06s\n",
      "lightGBM Training [t401] start!\n",
      "lightGBM Training Done [t401], spent: 2.06s\n",
      "lightGBM Training [t417] start!\n",
      "lightGBM Training Done [t417], spent: 2.07s\n",
      "lightGBM Training [t433] start!\n",
      "lightGBM Training Done [t433], spent: 2.32s\n",
      "lightGBM Training [t449] start!\n",
      "lightGBM Training Done [t449], spent: 2.04s\n",
      "lightGBM Training [t465] start!\n",
      "lightGBM Training Done [t465], spent: 2.07s\n",
      "lightGBM Training [t481] start!\n",
      "lightGBM Training Done [t481], spent: 2.05s\n",
      "lightGBM Training [t513] start!\n",
      "lightGBM Training Done [t513], spent: 2.07s\n",
      "lightGBM Training [t545] start!\n",
      "lightGBM Training Done [t545], spent: 2.07s\n",
      "lightGBM Training [t577] start!\n",
      "lightGBM Training Done [t577], spent: 2.07s\n",
      "lightGBM Training [t609] start!\n",
      "lightGBM Training Done [t609], spent: 2.11s\n",
      "lightGBM Training [t641] start!\n",
      "lightGBM Training Done [t641], spent: 2.06s\n",
      "lightGBM Training [t673] start!\n",
      "lightGBM Training Done [t673], spent: 2.05s\n",
      "lightGBM Training [t705] start!\n",
      "lightGBM Training Done [t705], spent: 2.65s\n",
      "lightGBM Training [t737] start!\n",
      "lightGBM Training Done [t737], spent: 2.55s\n",
      "lightGBM Training [t769] start!\n",
      "lightGBM Training Done [t769], spent: 2.28s\n",
      "lightGBM Training [t801] start!\n",
      "lightGBM Training Done [t801], spent: 2.12s\n",
      "lightGBM Training [t833] start!\n",
      "lightGBM Training Done [t833], spent: 3.35s\n",
      "lightGBM Training [t865] start!\n",
      "lightGBM Training Done [t865], spent: 2.36s\n",
      "lightGBM Training [t897] start!\n",
      "lightGBM Training Done [t897], spent: 2.22s\n",
      "lightGBM Training [t929] start!\n",
      "lightGBM Training Done [t929], spent: 2.66s\n",
      "lightGBM Training [t961] start!\n",
      "lightGBM Training Done [t961], spent: 2.03s\n",
      "lightGBM Training [t993] start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightGBM Training Done [t993], spent: 2.04s\n",
      "lightGBM Training [t1025] start!\n",
      "lightGBM Training Done [t1025], spent: 2.45s\n",
      "lightGBM Training [t1057] start!\n",
      "lightGBM Training Done [t1057], spent: 2.78s\n",
      "lightGBM Training [t1089] start!\n",
      "lightGBM Training Done [t1089], spent: 2.65s\n",
      "lightGBM Training [t1121] start!\n",
      "lightGBM Training Done [t1121], spent: 2.49s\n",
      "lightGBM Training [t1153] start!\n",
      "lightGBM Training Done [t1153], spent: 3.58s\n",
      "lightGBM Training [t1185] start!\n",
      "lightGBM Training Done [t1185], spent: 2.13s\n",
      "lightGBM Training [t1217] start!\n",
      "lightGBM Training Done [t1217], spent: 3.00s\n",
      "lightGBM Training [t1249] start!\n",
      "lightGBM Training Done [t1249], spent: 3.35s\n",
      "lightGBM Training [t1281] start!\n",
      "lightGBM Training Done [t1281], spent: 3.91s\n",
      "lightGBM Training [t1313] start!\n",
      "lightGBM Training Done [t1313], spent: 4.08s\n",
      "lightGBM Training [t1345] start!\n",
      "lightGBM Training Done [t1345], spent: 4.21s\n",
      "lightGBM Training [t1377] start!\n",
      "lightGBM Training Done [t1377], spent: 3.32s\n",
      "lightGBM Training [t1409] start!\n",
      "lightGBM Training Done [t1409], spent: 4.66s\n",
      "All Training Done, spent: 337.97s\n",
      "Start Test Models with Test Dataset!\n",
      "[0/120]t1 start!\n",
      "t1loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t1.pkl\n",
      "[0/120]t1 lightGBM Test MAE: 0.22, spent: 0.30s\n",
      "[1/120]t2 start!\n",
      "t2loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t2.pkl\n",
      "[1/120]t2 lightGBM Test MAE: 0.23, spent: 0.30s\n",
      "[2/120]t3 start!\n",
      "t3loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t3.pkl\n",
      "[2/120]t3 lightGBM Test MAE: 0.24, spent: 0.30s\n",
      "[3/120]t4 start!\n",
      "t4loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t4.pkl\n",
      "[3/120]t4 lightGBM Test MAE: 0.24, spent: 0.31s\n",
      "[4/120]t5 start!\n",
      "t5loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t5.pkl\n",
      "[4/120]t5 lightGBM Test MAE: 0.25, spent: 0.30s\n",
      "[5/120]t6 start!\n",
      "t6loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t6.pkl\n",
      "[5/120]t6 lightGBM Test MAE: 0.25, spent: 0.30s\n",
      "[6/120]t7 start!\n",
      "t7loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t7.pkl\n",
      "[6/120]t7 lightGBM Test MAE: 0.26, spent: 0.30s\n",
      "[7/120]t8 start!\n",
      "t8loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t8.pkl\n",
      "[7/120]t8 lightGBM Test MAE: 0.26, spent: 0.31s\n",
      "[8/120]t9 start!\n",
      "t9loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t9.pkl\n",
      "[8/120]t9 lightGBM Test MAE: 0.27, spent: 0.32s\n",
      "[9/120]t10 start!\n",
      "t10loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t10.pkl\n",
      "[9/120]t10 lightGBM Test MAE: 0.27, spent: 0.32s\n",
      "[10/120]t11 start!\n",
      "t11loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t11.pkl\n",
      "[10/120]t11 lightGBM Test MAE: 0.27, spent: 0.31s\n",
      "[11/120]t12 start!\n",
      "t12loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t12.pkl\n",
      "[11/120]t12 lightGBM Test MAE: 0.27, spent: 0.31s\n",
      "[12/120]t13 start!\n",
      "t13loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t13.pkl\n",
      "[12/120]t13 lightGBM Test MAE: 0.28, spent: 0.33s\n",
      "[13/120]t14 start!\n",
      "t14loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t14.pkl\n",
      "[13/120]t14 lightGBM Test MAE: 0.28, spent: 0.30s\n",
      "[14/120]t15 start!\n",
      "t15loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t15.pkl\n",
      "[14/120]t15 lightGBM Test MAE: 0.28, spent: 0.30s\n",
      "[15/120]t16 start!\n",
      "t16loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t16.pkl\n",
      "[15/120]t16 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[16/120]t17 start!\n",
      "t17loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t17.pkl\n",
      "[16/120]t17 lightGBM Test MAE: 0.31, spent: 0.29s\n",
      "[17/120]t18 start!\n",
      "t18loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t18.pkl\n",
      "[17/120]t18 lightGBM Test MAE: 0.30, spent: 0.30s\n",
      "[18/120]t19 start!\n",
      "t19loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t19.pkl\n",
      "[18/120]t19 lightGBM Test MAE: 0.32, spent: 0.29s\n",
      "[19/120]t20 start!\n",
      "t20loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t20.pkl\n",
      "[19/120]t20 lightGBM Test MAE: 0.32, spent: 0.30s\n",
      "[20/120]t21 start!\n",
      "t21loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t21.pkl\n",
      "[20/120]t21 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[21/120]t22 start!\n",
      "t22loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t22.pkl\n",
      "[21/120]t22 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[22/120]t23 start!\n",
      "t23loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t23.pkl\n",
      "[22/120]t23 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[23/120]t24 start!\n",
      "t24loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t24.pkl\n",
      "[23/120]t24 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[24/120]t25 start!\n",
      "t25loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t25.pkl\n",
      "[24/120]t25 lightGBM Test MAE: 0.32, spent: 0.29s\n",
      "[25/120]t26 start!\n",
      "t26loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t26.pkl\n",
      "[25/120]t26 lightGBM Test MAE: 0.33, spent: 0.28s\n",
      "[26/120]t27 start!\n",
      "t27loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t27.pkl\n",
      "[26/120]t27 lightGBM Test MAE: 0.33, spent: 0.36s\n",
      "[27/120]t28 start!\n",
      "t28loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t28.pkl\n",
      "[27/120]t28 lightGBM Test MAE: 0.33, spent: 0.32s\n",
      "[28/120]t29 start!\n",
      "t29loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t29.pkl\n",
      "[28/120]t29 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[29/120]t30 start!\n",
      "t30loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t30.pkl\n",
      "[29/120]t30 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[30/120]t31 start!\n",
      "t31loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t31.pkl\n",
      "[30/120]t31 lightGBM Test MAE: 0.32, spent: 0.29s\n",
      "[31/120]t33 start!\n",
      "t33loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t33.pkl\n",
      "[31/120]t33 lightGBM Test MAE: 0.32, spent: 0.30s\n",
      "[32/120]t35 start!\n",
      "t35loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t35.pkl\n",
      "[32/120]t35 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[33/120]t37 start!\n",
      "t37loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t37.pkl\n",
      "[33/120]t37 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[34/120]t39 start!\n",
      "t39loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t39.pkl\n",
      "[34/120]t39 lightGBM Test MAE: 0.33, spent: 0.28s\n",
      "[35/120]t41 start!\n",
      "t41loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t41.pkl\n",
      "[35/120]t41 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[36/120]t43 start!\n",
      "t43loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t43.pkl\n",
      "[36/120]t43 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[37/120]t45 start!\n",
      "t45loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t45.pkl\n",
      "[37/120]t45 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[38/120]t47 start!\n",
      "t47loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t47.pkl\n",
      "[38/120]t47 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[39/120]t49 start!\n",
      "t49loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t49.pkl\n",
      "[39/120]t49 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[40/120]t51 start!\n",
      "t51loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t51.pkl\n",
      "[40/120]t51 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[41/120]t53 start!\n",
      "t53loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t53.pkl\n",
      "[41/120]t53 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[42/120]t55 start!\n",
      "t55loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t55.pkl\n",
      "[42/120]t55 lightGBM Test MAE: 0.32, spent: 0.29s\n",
      "[43/120]t57 start!\n",
      "t57loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t57.pkl\n",
      "[43/120]t57 lightGBM Test MAE: 0.32, spent: 0.30s\n",
      "[44/120]t59 start!\n",
      "t59loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t59.pkl\n",
      "[44/120]t59 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[45/120]t61 start!\n",
      "t61loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t61.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45/120]t61 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[46/120]t65 start!\n",
      "t65loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t65.pkl\n",
      "[46/120]t65 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[47/120]t69 start!\n",
      "t69loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t69.pkl\n",
      "[47/120]t69 lightGBM Test MAE: 0.33, spent: 0.30s\n",
      "[48/120]t73 start!\n",
      "t73loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t73.pkl\n",
      "[48/120]t73 lightGBM Test MAE: 0.33, spent: 0.30s\n",
      "[49/120]t77 start!\n",
      "t77loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t77.pkl\n",
      "[49/120]t77 lightGBM Test MAE: 0.33, spent: 0.30s\n",
      "[50/120]t81 start!\n",
      "t81loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t81.pkl\n",
      "[50/120]t81 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[51/120]t85 start!\n",
      "t85loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t85.pkl\n",
      "[51/120]t85 lightGBM Test MAE: 0.34, spent: 0.30s\n",
      "[52/120]t89 start!\n",
      "t89loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t89.pkl\n",
      "[52/120]t89 lightGBM Test MAE: 0.33, spent: 0.29s\n",
      "[53/120]t93 start!\n",
      "t93loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t93.pkl\n",
      "[53/120]t93 lightGBM Test MAE: 0.32, spent: 0.30s\n",
      "[54/120]t97 start!\n",
      "t97loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t97.pkl\n",
      "[54/120]t97 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[55/120]t101 start!\n",
      "t101loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t101.pkl\n",
      "[55/120]t101 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[56/120]t105 start!\n",
      "t105loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t105.pkl\n",
      "[56/120]t105 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[57/120]t109 start!\n",
      "t109loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t109.pkl\n",
      "[57/120]t109 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[58/120]t113 start!\n",
      "t113loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t113.pkl\n",
      "[58/120]t113 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[59/120]t117 start!\n",
      "t117loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t117.pkl\n",
      "[59/120]t117 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[60/120]t121 start!\n",
      "t121loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t121.pkl\n",
      "[60/120]t121 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[61/120]t129 start!\n",
      "t129loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t129.pkl\n",
      "[61/120]t129 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[62/120]t137 start!\n",
      "t137loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t137.pkl\n",
      "[62/120]t137 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[63/120]t145 start!\n",
      "t145loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t145.pkl\n",
      "[63/120]t145 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[64/120]t153 start!\n",
      "t153loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t153.pkl\n",
      "[64/120]t153 lightGBM Test MAE: 0.34, spent: 0.30s\n",
      "[65/120]t161 start!\n",
      "t161loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t161.pkl\n",
      "[65/120]t161 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[66/120]t169 start!\n",
      "t169loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t169.pkl\n",
      "[66/120]t169 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[67/120]t177 start!\n",
      "t177loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t177.pkl\n",
      "[67/120]t177 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[68/120]t185 start!\n",
      "t185loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t185.pkl\n",
      "[68/120]t185 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[69/120]t193 start!\n",
      "t193loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t193.pkl\n",
      "[69/120]t193 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[70/120]t201 start!\n",
      "t201loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t201.pkl\n",
      "[70/120]t201 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[71/120]t209 start!\n",
      "t209loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t209.pkl\n",
      "[71/120]t209 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[72/120]t217 start!\n",
      "t217loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t217.pkl\n",
      "[72/120]t217 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[73/120]t225 start!\n",
      "t225loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t225.pkl\n",
      "[73/120]t225 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[74/120]t233 start!\n",
      "t233loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t233.pkl\n",
      "[74/120]t233 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[75/120]t241 start!\n",
      "t241loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t241.pkl\n",
      "[75/120]t241 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[76/120]t257 start!\n",
      "t257loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t257.pkl\n",
      "[76/120]t257 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[77/120]t273 start!\n",
      "t273loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t273.pkl\n",
      "[77/120]t273 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[78/120]t289 start!\n",
      "t289loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t289.pkl\n",
      "[78/120]t289 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[79/120]t305 start!\n",
      "t305loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t305.pkl\n",
      "[79/120]t305 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[80/120]t321 start!\n",
      "t321loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t321.pkl\n",
      "[80/120]t321 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[81/120]t337 start!\n",
      "t337loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t337.pkl\n",
      "[81/120]t337 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[82/120]t353 start!\n",
      "t353loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t353.pkl\n",
      "[82/120]t353 lightGBM Test MAE: 0.34, spent: 0.28s\n",
      "[83/120]t369 start!\n",
      "t369loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t369.pkl\n",
      "[83/120]t369 lightGBM Test MAE: 0.35, spent: 0.29s\n",
      "[84/120]t385 start!\n",
      "t385loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t385.pkl\n",
      "[84/120]t385 lightGBM Test MAE: 0.35, spent: 0.29s\n",
      "[85/120]t401 start!\n",
      "t401loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t401.pkl\n",
      "[85/120]t401 lightGBM Test MAE: 0.35, spent: 0.29s\n",
      "[86/120]t417 start!\n",
      "t417loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t417.pkl\n",
      "[86/120]t417 lightGBM Test MAE: 0.35, spent: 0.28s\n",
      "[87/120]t433 start!\n",
      "t433loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t433.pkl\n",
      "[87/120]t433 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[88/120]t449 start!\n",
      "t449loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t449.pkl\n",
      "[88/120]t449 lightGBM Test MAE: 0.35, spent: 0.28s\n",
      "[89/120]t465 start!\n",
      "t465loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t465.pkl\n",
      "[89/120]t465 lightGBM Test MAE: 0.35, spent: 0.28s\n",
      "[90/120]t481 start!\n",
      "t481loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t481.pkl\n",
      "[90/120]t481 lightGBM Test MAE: 0.35, spent: 0.28s\n",
      "[91/120]t513 start!\n",
      "t513loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t513.pkl\n",
      "[91/120]t513 lightGBM Test MAE: 0.35, spent: 0.29s\n",
      "[92/120]t545 start!\n",
      "t545loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t545.pkl\n",
      "[92/120]t545 lightGBM Test MAE: 0.35, spent: 0.29s\n",
      "[93/120]t577 start!\n",
      "t577loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t577.pkl\n",
      "[93/120]t577 lightGBM Test MAE: 0.35, spent: 0.28s\n",
      "[94/120]t609 start!\n",
      "t609loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t609.pkl\n",
      "[94/120]t609 lightGBM Test MAE: 0.35, spent: 0.28s\n",
      "[95/120]t641 start!\n",
      "t641loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t641.pkl\n",
      "[95/120]t641 lightGBM Test MAE: 0.35, spent: 0.29s\n",
      "[96/120]t673 start!\n",
      "t673loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t673.pkl\n",
      "[96/120]t673 lightGBM Test MAE: 0.35, spent: 0.29s\n",
      "[97/120]t705 start!\n",
      "t705loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t705.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97/120]t705 lightGBM Test MAE: 0.35, spent: 0.29s\n",
      "[98/120]t737 start!\n",
      "t737loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t737.pkl\n",
      "[98/120]t737 lightGBM Test MAE: 0.35, spent: 0.29s\n",
      "[99/120]t769 start!\n",
      "t769loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t769.pkl\n",
      "[99/120]t769 lightGBM Test MAE: 0.35, spent: 0.29s\n",
      "[100/120]t801 start!\n",
      "t801loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t801.pkl\n",
      "[100/120]t801 lightGBM Test MAE: 0.35, spent: 0.29s\n",
      "[101/120]t833 start!\n",
      "t833loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t833.pkl\n",
      "[101/120]t833 lightGBM Test MAE: 0.34, spent: 0.30s\n",
      "[102/120]t865 start!\n",
      "t865loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t865.pkl\n",
      "[102/120]t865 lightGBM Test MAE: 0.35, spent: 0.29s\n",
      "[103/120]t897 start!\n",
      "t897loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t897.pkl\n",
      "[103/120]t897 lightGBM Test MAE: 0.35, spent: 0.29s\n",
      "[104/120]t929 start!\n",
      "t929loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t929.pkl\n",
      "[104/120]t929 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[105/120]t961 start!\n",
      "t961loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t961.pkl\n",
      "[105/120]t961 lightGBM Test MAE: 0.35, spent: 0.28s\n",
      "[106/120]t993 start!\n",
      "t993loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t993.pkl\n",
      "[106/120]t993 lightGBM Test MAE: 0.35, spent: 0.28s\n",
      "[107/120]t1025 start!\n",
      "t1025loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t1025.pkl\n",
      "[107/120]t1025 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[108/120]t1057 start!\n",
      "t1057loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t1057.pkl\n",
      "[108/120]t1057 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[109/120]t1089 start!\n",
      "t1089loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t1089.pkl\n",
      "[109/120]t1089 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[110/120]t1121 start!\n",
      "t1121loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t1121.pkl\n",
      "[110/120]t1121 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[111/120]t1153 start!\n",
      "t1153loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t1153.pkl\n",
      "[111/120]t1153 lightGBM Test MAE: 0.34, spent: 0.30s\n",
      "[112/120]t1185 start!\n",
      "t1185loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t1185.pkl\n",
      "[112/120]t1185 lightGBM Test MAE: 0.35, spent: 0.29s\n",
      "[113/120]t1217 start!\n",
      "t1217loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t1217.pkl\n",
      "[113/120]t1217 lightGBM Test MAE: 0.35, spent: 0.29s\n",
      "[114/120]t1249 start!\n",
      "t1249loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t1249.pkl\n",
      "[114/120]t1249 lightGBM Test MAE: 0.34, spent: 0.29s\n",
      "[115/120]t1281 start!\n",
      "t1281loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t1281.pkl\n",
      "[115/120]t1281 lightGBM Test MAE: 0.34, spent: 0.30s\n",
      "[116/120]t1313 start!\n",
      "t1313loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t1313.pkl\n",
      "[116/120]t1313 lightGBM Test MAE: 0.35, spent: 0.51s\n",
      "[117/120]t1345 start!\n",
      "t1345loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t1345.pkl\n",
      "[117/120]t1345 lightGBM Test MAE: 0.34, spent: 0.30s\n",
      "[118/120]t1377 start!\n",
      "t1377loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t1377.pkl\n",
      "[118/120]t1377 lightGBM Test MAE: 0.35, spent: 0.30s\n",
      "[119/120]t1409 start!\n",
      "t1409loading model file:./eptest/t1/da95ef0e-6bfd-11ea-894b-258eed843d36/lightgbm_t1409.pkl\n",
      "[119/120]t1409 lightGBM Test MAE: 0.35, spent: 0.31s\n",
      "TrainAndTest All Finished!\n",
      "All Prediction(Test) Done, spent: 37.33s\n",
      "All Finished and Results Saved!\n",
      "Start Run da9c4f66-6bfd-11ea-894b-258eed843d36\n",
      "Start FNN [da9c4f66-6bfd-11ea-894b-258eed843d36] models Training and Test!\n",
      "Directory  ./eptest/t1/da9c4f66-6bfd-11ea-894b-258eed843d36/  Created \n",
      "FNN Training [t1] start!\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 64)             432064    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 1350)           433350    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1350)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1351      \n",
      "=================================================================\n",
      "Total params: 866,765\n",
      "Trainable params: 866,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 21610 samples, validate on 2161 samples\n",
      "Epoch 1/100\n",
      " 7000/21610 [========>.....................] - ETA: 2s - loss: 0.2243 - accuracy: 0.5137FNN Training [t16] start!\n",
      " 8000/21610 [==========>...................] - ETA: 2s - loss: 0.2239 - accuracy: 0.5119Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 64)             432064    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 1350)           433350    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1350)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1351      \n",
      "=================================================================\n",
      "Total params: 866,765\n",
      "Trainable params: 866,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "13000/21610 [=================>............] - ETA: 1s - loss: 0.2274 - accuracy: 0.5062Train on 21610 samples, validate on 2161 samples\n",
      "Epoch 1/100\n",
      "21610/21610 [==============================] - 3s 161us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 2/100\n",
      "21610/21610 [==============================] - 4s 199us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 2/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 3/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 3/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 4/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 4/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 5/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 5/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 6/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 7/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 7/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 8/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 8/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 9/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 9/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 10/100\n",
      "21610/21610 [==============================] - 4s 192us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 10/100\n",
      "21610/21610 [==============================] - 4s 192us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 11/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 11/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 12/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 12/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 13/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 13/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 14/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 14/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 15/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 15/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 16/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 16/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 17/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 17/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 18/100\n",
      "21610/21610 [==============================] - 4s 191us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 18/100\n",
      "21610/21610 [==============================] - 4s 191us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 19/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 19/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 20/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 20/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 21/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 21/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 22/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 22/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 23/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 23/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 24/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 24/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 25/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 25/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 26/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 26/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 27/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 27/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 28/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 28/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 29/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 29/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 30/100\n",
      "21610/21610 [==============================] - 4s 191us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 30/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 31/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 31/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 32/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 32/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 33/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 33/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 34/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 35/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 35/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 36/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 36/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 37/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 37/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 38/100\n",
      "21610/21610 [==============================] - 4s 191us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 38/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 39/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 39/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 40/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 40/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 41/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 41/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 42/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 42/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 43/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 43/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 44/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 44/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 45/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 45/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 46/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 46/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 47/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 47/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 48/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 48/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 49/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 49/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 50/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 50/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 51/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 51/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 52/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 52/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 53/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 53/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 54/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 54/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 55/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 55/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 56/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 56/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 57/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 57/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 58/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 58/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 59/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 59/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 60/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 60/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21610/21610 [==============================] - 4s 190us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 61/100\n",
      "21610/21610 [==============================] - 4s 191us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 62/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 62/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 63/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 63/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 64/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 64/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 65/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 65/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 66/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 66/100\n",
      "21610/21610 [==============================] - 4s 192us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 67/100\n",
      "21610/21610 [==============================] - 4s 194us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 67/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 68/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 68/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 69/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 69/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 70/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 70/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 71/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 71/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 72/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 72/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 73/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 73/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 74/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 74/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 75/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 75/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 76/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 76/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 77/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 77/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 78/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 78/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 79/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 79/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 80/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 80/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 81/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 81/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 82/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 82/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 83/100\n",
      "21610/21610 [==============================] - 4s 182us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 83/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 84/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 84/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 85/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 85/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 86/100\n",
      "21610/21610 [==============================] - 4s 193us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 86/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 87/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 87/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 88/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 89/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 89/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 90/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 90/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 91/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 91/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 92/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 92/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 93/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 93/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 94/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 94/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 95/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 95/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 96/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 96/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 97/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 97/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 98/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 98/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 99/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 99/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      "Epoch 100/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 100/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5083 - val_loss: 0.2004 - val_accuracy: 0.1842\n",
      " 6000/21610 [=======>......................] - ETA: 2s - loss: 0.2266 - accuracy: 0.4968FNN Training Done [t1], spent: 404.03s\n",
      "FNN Training [t2] start!\n",
      " 7000/21610 [========>.....................] - ETA: 2s - loss: 0.2233 - accuracy: 0.5014Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 64)             432064    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 1, 1350)           433350    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1350)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1351      \n",
      "=================================================================\n",
      "Total params: 866,765\n",
      "Trainable params: 866,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "13000/21610 [=================>............] - ETA: 1s - loss: 0.2279 - accuracy: 0.5038Train on 21610 samples, validate on 2161 samples\n",
      "Epoch 1/100\n",
      "21610/21610 [==============================] - 3s 156us/step - loss: 0.2251 - accuracy: 0.5069 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      " 9000/21610 [===========>..................] - ETA: 2s - loss: 0.2244 - accuracy: 0.5082FNN Training Done [t16], spent: 404.75s\n",
      "FNN Training [t17] start!\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 64)             432064    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 1, 1350)           433350    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1350)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1351      \n",
      "=================================================================\n",
      "10000/21610 [============>.................] - ETA: 2s - loss: 0.2259 - accuracy: 0.5101Total params: 866,765\n",
      "Trainable params: 866,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "16000/21610 [=====================>........] - ETA: 0s - loss: 0.2224 - accuracy: 0.5095Train on 21610 samples, validate on 2161 samples\n",
      "Epoch 1/100\n",
      "21610/21610 [==============================] - 4s 166us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 2/100\n",
      "21610/21610 [==============================] - 4s 200us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 2/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 3/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 3/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 4/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 4/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 5/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 6/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 6/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 7/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 7/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 8/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 8/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 9/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 9/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 10/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 10/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 11/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 11/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 12/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 12/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 13/100\n",
      "21610/21610 [==============================] - 4s 191us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 13/100\n",
      "21610/21610 [==============================] - 4s 191us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 14/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 14/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 15/100\n",
      "21610/21610 [==============================] - 4s 191us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 15/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 16/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 16/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 17/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 17/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 18/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 18/100\n",
      "21610/21610 [==============================] - 4s 191us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 19/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 19/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 20/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 20/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 21/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 21/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 22/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 22/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 23/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 23/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 24/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 24/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 25/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 25/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 26/100\n",
      "21610/21610 [==============================] - 4s 195us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 26/100\n",
      "21610/21610 [==============================] - 4s 193us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 27/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 27/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 28/100\n",
      "21610/21610 [==============================] - 4s 192us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 28/100\n",
      "21610/21610 [==============================] - 4s 191us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 29/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 29/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 30/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 30/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 31/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 31/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 32/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 32/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 33/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 34/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 34/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 35/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 35/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 36/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 36/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 37/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 37/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 38/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 38/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 39/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 39/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 40/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 40/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 41/100\n",
      "21610/21610 [==============================] - 4s 195us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 41/100\n",
      "21610/21610 [==============================] - 4s 196us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 42/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 42/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 43/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 43/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 44/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 44/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 45/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 45/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 46/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 46/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 47/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 47/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 48/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 48/100\n",
      "21610/21610 [==============================] - 4s 191us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 49/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 49/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 50/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 50/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 51/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 51/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 52/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 52/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 53/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 53/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 54/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 54/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 55/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 55/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 56/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 56/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 57/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 57/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 58/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 58/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 59/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 59/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 60/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 61/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 61/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 62/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 62/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 63/100\n",
      "21610/21610 [==============================] - 4s 191us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 63/100\n",
      "21610/21610 [==============================] - 4s 193us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 64/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 64/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 65/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 65/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 66/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 66/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 67/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 67/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 68/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 68/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 69/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 69/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 70/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 70/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 71/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 71/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 72/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 72/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 73/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 73/100\n",
      "21610/21610 [==============================] - 4s 192us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 74/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 74/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 75/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 75/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 76/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 76/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 77/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 77/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 78/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 78/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 79/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 79/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 80/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 80/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 81/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 81/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 82/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 82/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 83/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 83/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 84/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 84/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 85/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 85/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 86/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 86/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 87/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 88/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 88/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 89/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 89/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 90/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 90/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 91/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 91/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 92/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 92/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 93/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 93/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 94/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 94/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 95/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 95/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 96/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 96/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 97/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 97/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 98/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 98/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 99/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 99/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      "Epoch 100/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "Epoch 100/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: 0.2238 - accuracy: 0.5082 - val_loss: 0.2002 - val_accuracy: 0.1846\n",
      " 7000/21610 [========>.....................] - ETA: 2s - loss: 0.2268 - accuracy: 0.5037FNN Training Done [t2], spent: 405.26s\n",
      "FNN Training [t3] start!\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1, 64)             432064    \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1, 1350)           433350    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1350)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1351      \n",
      "=================================================================\n",
      "Total params: 866,765\n",
      "Trainable params: 866,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "13000/21610 [=================>............] - ETA: 1s - loss: 0.2263 - accuracy: 0.5065Train on 21610 samples, validate on 2161 samples\n",
      "Epoch 1/100\n",
      "21610/21610 [==============================] - 3s 162us/step - loss: 0.2252 - accuracy: 0.5068 - val_loss: 0.1996 - val_accuracy: 0.1874\n",
      "10000/21610 [============>.................] - ETA: 2s - loss: nan - accuracy: 0.0000e+00FNN Training Done [t17], spent: 405.31s\n",
      "FNN Training [t18] start!\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1, 64)             432064    \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1, 1350)           433350    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1350)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1351      \n",
      "=================================================================\n",
      "Total params: 866,765\n",
      "Trainable params: 866,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "16000/21610 [=====================>........] - ETA: 0s - loss: nan - accuracy: 0.0000e+00Train on 21610 samples, validate on 2161 samples\n",
      "Epoch 1/100\n",
      "21610/21610 [==============================] - 4s 169us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "21610/21610 [==============================] - 4s 200us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "21610/21610 [==============================] - 4s 192us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "21610/21610 [==============================] - 4s 192us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "21610/21610 [==============================] - 4s 182us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "21610/21610 [==============================] - 4s 192us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "21610/21610 [==============================] - 4s 191us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "21610/21610 [==============================] - 4s 190us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "21610/21610 [==============================] - 4s 195us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "21610/21610 [==============================] - 4s 195us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "21610/21610 [==============================] - 4s 192us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "21610/21610 [==============================] - 4s 193us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      " 7000/21610 [========>.....................] - ETA: 2s - loss: nan - accuracy: 0.0000e+00FNN Training Done [t3], spent: 404.68s\n",
      "FNN Training [t4] start!\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 1, 64)             432064    \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 1, 1350)           433350    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1350)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 1351      \n",
      "=================================================================\n",
      "Total params: 866,765\n",
      "Trainable params: 866,765\n",
      "Non-trainable params: 0\n",
      " 8000/21610 [==========>...................] - ETA: 2s - loss: nan - accuracy: 0.0000e+00_________________________________________________________________\n",
      "13000/21610 [=================>............] - ETA: 1s - loss: nan - accuracy: 0.0000e+00Train on 21610 samples, validate on 2161 samples\n",
      "Epoch 1/100\n",
      "21610/21610 [==============================] - 3s 159us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "10000/21610 [============>.................] - ETA: 2s - loss: nan - accuracy: 0.0000e+00FNN Training Done [t18], spent: 404.64s\n",
      "FNN Training [t19] start!\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 1, 64)             432064    \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 1, 1350)           433350    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1, 1350)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1350)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 1351      \n",
      "=================================================================\n",
      "11000/21610 [==============>...............] - ETA: 1s - loss: nan - accuracy: 0.0000e+00Total params: 866,765\n",
      "Trainable params: 866,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "16000/21610 [=====================>........] - ETA: 0s - loss: nan - accuracy: 0.0000e+00Train on 21610 samples, validate on 2161 samples\n",
      "Epoch 1/100\n",
      "21610/21610 [==============================] - 4s 169us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "21610/21610 [==============================] - 4s 196us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "21610/21610 [==============================] - 4s 191us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "21610/21610 [==============================] - 4s 193us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "21610/21610 [==============================] - 4s 187us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "21610/21610 [==============================] - 4s 188us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "21610/21610 [==============================] - 4s 189us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "21610/21610 [==============================] - 4s 192us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "21610/21610 [==============================] - 4s 185us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "21610/21610 [==============================] - 4s 186us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "21610/21610 [==============================] - 4s 183us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "21610/21610 [==============================] - 4s 184us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      " 6000/21610 [=======>......................] - ETA: 2s - loss: nan - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "## run one\n",
    "#exp.run(\"58b41e9e-6742-11ea-b658-8d7a6e287413\")\n",
    "\n",
    "##or run all\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show features list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T03:49:59.779212Z",
     "start_time": "2020-03-22T03:49:59.770807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Temp', 'Wind', 'Humidity', 'Barometer', 'Extreme_weather', 'min_dis0.05', 'num_of_poi0.05', 'num_of_open_poi0.05', 'mean_dis0.05', 'min_dis0.1', 'num_of_poi0.1', 'num_of_open_poi0.1', 'mean_dis0.1', 'min_dis0.2', 'num_of_poi0.2', 'num_of_open_poi0.2', 'mean_dis0.2', 'min_dis0.3', 'num_of_poi0.3', 'num_of_open_poi0.3', 'mean_dis0.3', 'min_dis0.4', 'num_of_poi0.4', 'num_of_open_poi0.4', 'mean_dis0.4', 'min_dis0.5', 'num_of_poi0.5', 'num_of_open_poi0.5', 'mean_dis0.5', 'min_dis0.8', 'num_of_poi0.8', 'num_of_open_poi0.8', 'mean_dis0.8', 'min_dis1.0', 'num_of_poi1.0', 'num_of_open_poi1.0', 'mean_dis1.0', 'availability', 'duration', 'Day', 'Hour', 'Minute', 'DayOfWeek', 'DayOfMonth', 'DayOfYear']\n"
     ]
    }
   ],
   "source": [
    "exp.showFeatureList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
